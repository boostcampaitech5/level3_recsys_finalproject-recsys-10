# kobert_rec


## SKT Brain / kobert 기반

> KoBERT[SKT Brain]  
> https://github.com/SKTBrain/KoBERT
>
> hugging face [KoBERT-Transformers]  
> https://huggingface.co/monologg/kobert

<br>

## 목표
---

사용자의 입력으로 평문을 받아들여, 해당 문장이 어떤 카테고리에 속하는지 예측하는 것이 목표입니다. 기존의 키워드 기반 검색과는 달리, 자연어 처리를 통해 보다 자연스러운 문장 분석을 구현하고자 합니다.

> 기존 검색 [키워드 기반]  
> ex) 떡볶이, 감자탕, 감바스...
>
> 새로운 검색 [평문 기반]  
> ex) 날씨가 추운데 따뜻한 국물 요리를 먹고 싶어...

<br>

## finetuning
---

### \- dataset

|    | name | cat1 | cat2 | cat3 | cat4 |
| -- | ---- | :----: | :----: | :----: | :----: |
| 0  | 짜장덮밥 황금레시피 한그릇 점심저녁메뉴 자취생요리 |1|12|23|52|
| 1  | 웰빙식단. 자연식으로 차린 밥상 |1|12|23|52|
| .. | ... | ... | ... | ... | ... |
| 198596 | 초간단 야식 전자렌지로 바삭한 라면땅 만들기 | 6 | 45 | 33 | 69 |

198596 rows × 5 columns

> cat1 : 방법별 [끓이기, 회, 데치기, 절임, 볶음, ...] - 14 types
>
> cat2 : 상황별 [일상, 술안주, 다이어트, 해장, ...] - 14 types
>
> cat3 : 재료별 [육류, 해물류, 밀가루, 소고기, 돼지고기, ...] - 16 types
>
> cat4 : 종류별 [국/탕, 찌개, 메인반찬, 밑반찬, ...] - 17 types

<br>

### \- 학습 방식

> name : [cat1, cat2, cat3, cat4]  
> 각각의 카테고리를 라벨로 하여 4개의 모델 학습

<br>

### \- test performance

| model_name | eval_loss | eval_f1 | train_loss |
| ---------- | :---------: | :-------: | :----------: |
| cat1_predict_model | 0.5656 | 0.7397 | 0.6648 |
| cat2_predict_model | 0.9613 | 0.4325 | 1.0304 |
| cat3_predict_model | 0.7866 | 0.7049 | 0.9383 |
| cat4_predict_model | 0.5565 | 0.7550 | 0.6669 |

<br>

## \- output
---
```
nlp model load: 6.56s
model process time: 0.53s
input: 술과 함께 먹기 좋은 음식
output: (4, 6, 9, 10)
```

> [방법: 튀김, 상황: 술안주, 재료: 기타, 종류: 기타]


<br>

## \- 한계
---

> 댓글 데이터로 학습을 시도하였지만, 댓글은 호불호에 대한 정보가 대부분이라 카테고리 분류를 하는데 학습 데이터로 사용할 수 없다.
>
> 제목 데이터는 작성자가 요리 이름 외에도 소개를 함께 다는 경우가 많아, 분류에서 충분한 성능을 예상하고 학습을 진행하였다.
>
> cat[1,3,4] 모델은 f1이 0.7대를 달성했지만, cat2의 모델의 성능이 떨어졌고, 원인은 상황별 카테고리 데이터이기 때문에 똑같은 종류의 메뉴라도 레시피 작성자가 어울리는 상황에 따라 분류게 되는 데이터였고, 개인의 주관이 많이 포함되어 있는 학습 데이터가 되면서 통일성이 없었다.